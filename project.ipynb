{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "import os.path\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "RESULT_FOLDER = 'results/'\n",
    "\n",
    "RATINGS_KINDLE = 'ratings_Kindle_Store.csv'\n",
    "REVIEWS_KINDLE = 'reviews_Kindle_Store_5.json'\n",
    "RATINGS_BOOKS = 'ratings_Books.csv'\n",
    "REVIEWS_BOOKS = 'reviews_Books_5.json'\n",
    "\n",
    "BOOKS_SELECTED_USERS = 'books_selected_users.parquet'\n",
    "KINDLE_SELECTED_USERS = 'kindle_selected_users.parquet'\n",
    "\n",
    "RATINGS_SCHEMA = StructType([\n",
    "    StructField(\"User\", StringType(), True),\n",
    "    StructField(\"Asin\", IntegerType(), True),\n",
    "    StructField(\"Ratings\", FloatType(), True),\n",
    "    StructField(\"Timestamp\", IntegerType(), True)])\n",
    "\n",
    "RATINGS_USER = 0\n",
    "RATINGS_ASIN = 1\n",
    "RATINGS_RATINGS = 2\n",
    "RATINGS_TIMESTAMP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_is_in(data, sel_users):\n",
    "    '''\n",
    "    Indicates if the user corresponding to a data sample belongs to the given array\n",
    "    :param : {'User', ...} tuple\n",
    "    :param : String[]\n",
    "    :return : Boolean\n",
    "    '''\n",
    "    return data['User'] in sel_users\n",
    "\n",
    "def write_parquet(df, path, force = False):\n",
    "    '''\n",
    "    Writes the given dataframe into a parquet file\n",
    "    :param : DataFrame\n",
    "    :param : String\n",
    "    :param : Boolean\n",
    "    '''\n",
    "    if os.path.isfile(path) and not force:\n",
    "        print(\"You already have an existing file with this name.\")\n",
    "        print(\"If you want to overwrite it, set force = True\")\n",
    "    else:\n",
    "        df.write.mode('overwrite').parquet(path)\n",
    "        \n",
    "def get_selected_users(regenerate = False):\n",
    "    '''\n",
    "    Return the dataframes containing the ratings on books and kindle of users who bought both type of platforms\n",
    "    :param : Boolean\n",
    "    :return : DataFrame, DataFrame\n",
    "    '''\n",
    "    books_distinct_users = df_ratings_books.select('User').distinct()\n",
    "    kindle_distinct_users = df_ratings_kindle.select('User').distinct()\n",
    "    both_users = books_distinct_users.join(kindle_distinct_users, 'User').distinct().persist()\n",
    "\n",
    "    if os.path.isfile(RESULT_FOLDER + BOOKS_SELECTED_USERS) and not regenerate:\n",
    "        books_sel_users = spark.read.parquet(RESULT_FOLDER + BOOKS_SELECTED_USERS)\n",
    "    else:\n",
    "        books_sel_users = df_ratings_books.join(both_users, 'User')\n",
    "        \n",
    "    if os.path.isfile(RESULT_FOLDER + KINDLE_SELECTED_USERS and not regenerate):\n",
    "        kindle_sel_users = spark.read.parquet(RESULT_FOLER + KINDLE_SELECTED_USERS)\n",
    "    else:\n",
    "        kindle_sel_users = df_ratings_kindle.join(both_users, 'User')\n",
    "        \n",
    "    return books_sel_users, kindle_sel_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(User='A2GZ9GFZV1LWB0', Asin=1603420304, Ratings=4.0, Timestamp=1405209600), Row(User='A1K7VSUDCVAPW8', Asin=1603420304, Ratings=3.0, Timestamp=1282176000), Row(User='A35J5XRE5ZT6H2', Asin=1603420304, Ratings=4.0, Timestamp=1365206400), Row(User='A3DGZNFSMNWSX5', Asin=1603420304, Ratings=4.0, Timestamp=1285632000), Row(User='A2CVDQ6H36L4VL', Asin=1603420304, Ratings=5.0, Timestamp=1342396800)]\n",
      "[Row(User='AH2L9G3DQHHAJ', Asin=116, Ratings=4.0, Timestamp=1019865600), Row(User='A2IIIDRK3PRRZY', Asin=116, Ratings=1.0, Timestamp=1395619200), Row(User='A1TADCM7YWPQ8M', Asin=868, Ratings=4.0, Timestamp=1031702400), Row(User='AWGH7V0BDOJKB', Asin=13714, Ratings=4.0, Timestamp=1383177600), Row(User='A3UTQPQPM4TQO0', Asin=13714, Ratings=5.0, Timestamp=1374883200)]\n"
     ]
    }
   ],
   "source": [
    "# Ratings datasets\n",
    "\n",
    "# Kindle\n",
    "df_ratings_kindle = spark.read.csv(DATA_FOLDER + RATINGS_KINDLE, header = False, schema = RATINGS_SCHEMA)\n",
    "print(df_ratings_kindle.head(5))\n",
    "\n",
    "# Books\n",
    "df_ratings_books = spark.read.csv(DATA_FOLDER + RATINGS_BOOKS, header = False, schema = RATINGS_SCHEMA)\n",
    "print(df_ratings_books.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(asin='B000F83SZQ', helpful=[0, 0], overall=5.0, reviewText=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", reviewTime='05 5, 2014', reviewerID='A1F6404F1VG29J', reviewerName='Avidreader', summary='Nice vintage story', unixReviewTime=1399248000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(asin='000100039X', helpful=[0, 0], overall=5.0, reviewText='Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!', reviewTime='12 16, 2012', reviewerID='A10000012B7CGYKOMPQ4L', reviewerName='Adam', summary='Wonderful!', unixReviewTime=1355616000)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviews datasets\n",
    "\n",
    "# Kindle\n",
    "df_reviews_kindle = spark.read.json(DATA_FOLDER + REVIEWS_KINDLE)\n",
    "print(df_reviews_kindle.head(1))\n",
    "\n",
    "# Books\n",
    "df_reviews_books = spark.read.json(DATA_FOLDER + REVIEWS_BOOKS)\n",
    "df_reviews_books.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic statistics\n",
    "Compute basic statistics on both datasets to verify if any difference exists between the two (very different means of the ratings would mean that one is generally prefered to the other, and very different variances would mean that some opinions on one of the support is not as unilateral as the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Books -- Count : 22507155, Mean : 4.29575892644, Variance : 1.23544712428\n",
      "-- Kindle -- Count : 3205467, Mean : 4.23210689737, Variance : 1.28548661246\n"
     ]
    }
   ],
   "source": [
    "# Averages\n",
    "\n",
    "# Books\n",
    "books_ratings = df_ratings_books.select('Ratings').rdd.map(lambda x : x[0]).persist()\n",
    "books_nb_sample = books_ratings.count()\n",
    "books_average = books_ratings.mean()\n",
    "books_variance = books_ratings.variance()\n",
    "books_ratings.unpersist()\n",
    "\n",
    "# Kindle\n",
    "kindle_ratings = df_ratings_kindle.select('Ratings').rdd.map(lambda x : x[0]).persist()\n",
    "kindle_nb_sample = kindle_ratings.count()\n",
    "kindle_average = kindle_ratings.mean()\n",
    "kindle_variance = kindle_ratings.variance()\n",
    "kindle_ratings.unpersist()\n",
    "\n",
    "# Print results\n",
    "print(\"-- Books -- Count : {}, Mean : {}, Variance : {}\".format(books_nb_sample, books_average, books_variance))\n",
    "print(\"-- Kindle -- Count : {}, Mean : {}, Variance : {}\".format(kindle_nb_sample, kindle_average, kindle_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "As expected, there is no differences in the basic statistics. The means are similar as well as the variances. This means that the two supports are appreciated the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select users who bought both Kindles and Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select users who bought both kindle and books\n",
    "books_distinct_users = df_ratings_books.select('User').distinct()\n",
    "kindle_distinct_users = df_ratings_kindle.select('User').distinct()\n",
    "#both_users = books_distinct_users.join(kindle_distinct_users, 'User').distinct().persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User='A00115723IFW2X9CUR3ST'),\n",
       " Row(User='A0161036FHTX15O1IG9T'),\n",
       " Row(User='A022858327OPV8WND7KHM'),\n",
       " Row(User='A028136819UJ4AT33LID2'),\n",
       " Row(User='A03032083BKNO315AGVT0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_distinct_users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet(books_distinct_users, RESULT_FOLDER + 'books_users')\n",
    "write_parquet(kindle_distinct_users, RESULT_FOLDER + 'kindle_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_distinct_users.registerTempTable(\"books_users\")\n",
    "kindle_distinct_users.registerTempTable(\"kindle_users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_users = spark.sql(\"\"\"SELECT books_users.User\n",
    "             FROM books_users \n",
    "             WHERE books_users.User IN \n",
    "             (SELECT kindle_users.User \n",
    "             FROM kindle_users)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet(df_common_users, RESULT_FOLDER + 'common_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_users = sqlContext.read.parquet(RESULT_FOLDER + \"common_users\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361903"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_common_users.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
